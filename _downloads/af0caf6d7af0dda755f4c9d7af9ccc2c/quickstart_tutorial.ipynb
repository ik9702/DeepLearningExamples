{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "N_Rh0tTnMOw3"
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n",
        "# https://pytorch.org/tutorials/beginner/colab\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPOttGnEMOw5"
      },
      "source": [
        "[Learn the Basics](intro.html) \\|\\| **Quickstart** \\|\\|\n",
        "[Tensors](tensorqs_tutorial.html) \\|\\| [Datasets &\n",
        "DataLoaders](data_tutorial.html) \\|\\|\n",
        "[Transforms](transforms_tutorial.html) \\|\\| [Build\n",
        "Model](buildmodel_tutorial.html) \\|\\|\n",
        "[Autograd](autogradqs_tutorial.html) \\|\\|\n",
        "[Optimization](optimization_tutorial.html) \\|\\| [Save & Load\n",
        "Model](saveloadrun_tutorial.html)\n",
        "\n",
        "Quickstart\n",
        "==========\n",
        "\n",
        "This section runs through the API for common tasks in machine learning.\n",
        "Refer to the links in each section to dive deeper.\n",
        "\n",
        "Working with data\n",
        "-----------------\n",
        "\n",
        "PyTorch has two [primitives to work with\n",
        "data](https://pytorch.org/docs/stable/data.html):\n",
        "`torch.utils.data.DataLoader` and `torch.utils.data.Dataset`. `Dataset`\n",
        "stores the samples and their corresponding labels, and `DataLoader`\n",
        "wraps an iterable around the `Dataset`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oCIOArg1MOw6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRCRBER-MOw6"
      },
      "source": [
        "PyTorch offers domain-specific libraries such as\n",
        "[TorchText](https://pytorch.org/text/stable/index.html),\n",
        "[TorchVision](https://pytorch.org/vision/stable/index.html), and\n",
        "[TorchAudio](https://pytorch.org/audio/stable/index.html), all of which\n",
        "include datasets. For this tutorial, we will be using a TorchVision\n",
        "dataset.\n",
        "\n",
        "The `torchvision.datasets` module contains `Dataset` objects for many\n",
        "real-world vision data like CIFAR, COCO ([full list\n",
        "here](https://pytorch.org/vision/stable/datasets.html)). In this\n",
        "tutorial, we use the FashionMNIST dataset. Every TorchVision `Dataset`\n",
        "includes two arguments: `transform` and `target_transform` to modify the\n",
        "samples and labels respectively.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AZmDMFuSMOw6",
        "outputId": "3abc4471-21f7-4111-a0aa-b99e6cad4af2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 20.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 348kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 6.18MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 17.0MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Download training data from open datasets.\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQvyc8yMMOw6"
      },
      "source": [
        "We pass the `Dataset` as an argument to `DataLoader`. This wraps an\n",
        "iterable over our dataset, and supports automatic batching, sampling,\n",
        "shuffling and multiprocess data loading. Here we define a batch size of\n",
        "64, i.e. each element in the dataloader iterable will return a batch of\n",
        "64 features and labels.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PDAlZmcXMOw6",
        "outputId": "7e9c5546-1fda-4899-ade0-dfd6920656a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(X[2, 0, :, :], cmap=\"gray\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cbjExOuYNEvo",
        "outputId": "451f84fb-a3c6-4c3d-eb22-732c75bb42ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0UnjfqmMOw7"
      },
      "source": [
        "Read more about [loading data in PyTorch](data_tutorial.html).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4Bm5DNcMOw7"
      },
      "source": [
        "------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OklU-s7eMOw7"
      },
      "source": [
        "Creating Models\n",
        "===============\n",
        "\n",
        "To define a neural network in PyTorch, we create a class that inherits\n",
        "from\n",
        "[nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html).\n",
        "We define the layers of the network in the `__init__` function and\n",
        "specify how data will pass through the network in the `forward`\n",
        "function. To accelerate operations in the neural network, we move it to\n",
        "the GPU or MPS if available.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIbhu3agMOw7"
      },
      "outputs": [],
      "source": [
        "# Get cpu, gpu or mps device for training.\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIrQFPbTMOw8"
      },
      "source": [
        "Read more about [building neural networks in\n",
        "PyTorch](buildmodel_tutorial.html).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oo8rzlPMMOw8"
      },
      "source": [
        "------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzrQUYmfMOw8"
      },
      "source": [
        "Optimizing the Model Parameters\n",
        "===============================\n",
        "\n",
        "To train a model, we need a [loss\n",
        "function](https://pytorch.org/docs/stable/nn.html#loss-functions) and an\n",
        "[optimizer](https://pytorch.org/docs/stable/optim.html).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZEEx_E5MOw8"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KIzTfP5MOw8"
      },
      "source": [
        "In a single training loop, the model makes predictions on the training\n",
        "dataset (fed to it in batches), and backpropagates the prediction error\n",
        "to adjust the model\\'s parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_yQOEvlMOw8"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWk2DEZdMOw8"
      },
      "source": [
        "We also check the model\\'s performance against the test dataset to\n",
        "ensure it is learning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8oNeTj6MOw8"
      },
      "outputs": [],
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czOUNLO5MOw8"
      },
      "source": [
        "The training process is conducted over several iterations (*epochs*).\n",
        "During each epoch, the model learns parameters to make better\n",
        "predictions. We print the model\\'s accuracy and loss at each epoch;\n",
        "we\\'d like to see the accuracy increase and the loss decrease with every\n",
        "epoch.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQk8RI10MOw8"
      },
      "outputs": [],
      "source": [
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmBbIeO6MOw8"
      },
      "source": [
        "Read more about [Training your model](optimization_tutorial.html).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hs1R-zD1MOw8"
      },
      "source": [
        "------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPds8M0cMOw8"
      },
      "source": [
        "Saving Models\n",
        "=============\n",
        "\n",
        "A common way to save a model is to serialize the internal state\n",
        "dictionary (containing the model parameters).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87VRhUjEMOw8"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvZIVP5CMOw9"
      },
      "source": [
        "Loading Models\n",
        "==============\n",
        "\n",
        "The process for loading a model includes re-creating the model structure\n",
        "and loading the state dictionary into it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyD4fnj2MOw9"
      },
      "outputs": [],
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "model.load_state_dict(torch.load(\"model.pth\", weights_only=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lhvzP0qMOw9"
      },
      "source": [
        "This model can now be used to make predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTaGpiT9MOw9"
      },
      "outputs": [],
      "source": [
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "x, y = test_data[0][0], test_data[0][1]\n",
        "with torch.no_grad():\n",
        "    x = x.to(device)\n",
        "    pred = model(x)\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgLEVCIoMOw9"
      },
      "source": [
        "Read more about [Saving & Loading your\n",
        "model](saveloadrun_tutorial.html).\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}